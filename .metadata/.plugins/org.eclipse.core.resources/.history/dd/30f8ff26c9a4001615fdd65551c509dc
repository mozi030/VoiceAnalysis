package NeuralNetwork;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;

public class NeuralNetwork {
	final static public int inputNum = 500;
	final static public ArrayList<String> outputs = new ArrayList<String>(
			Arrays.asList("down", "jump", "left", "move", "right", "shoot", "speedup", "up"));
	public static Node allNodes[][];

	final static public int hiddenLayerNum = 2;
	final static public int affectRange = 5;
	final static public float weightInitialValue = 0.01f;
	final static public float learningRate = 0.1f;

	public NeuralNetwork() throws Exception {
		allNodes = new Node[hiddenLayerNum + 2][];
		allNodes[0] = new Node[inputNum];
		//first layer, the input layer
		for (int j = 0; j < inputNum; j++) {
			allNodes[0][j].lastNodeIndexAndWeight = null;
			int begin = j - affectRange / 2;
			if (begin < 0) {
				begin = 0;
			}
			int end = j + affectRange / 2;
			if (end >= inputNum) {
				end = inputNum - 1;
			}
			if (end < begin) {
				throw new Exception("end < begin");
			}
			allNodes[0][j].nextNodeIndexAndWeight = new HashMap<>();
			for (int k = begin; k <= end; k++) {
				allNodes[0][j].nextNodeIndexAndWeight.put(k, weightInitialValue);
			}
		}
		
		//middle layers, the hidden layers
		for (int i = 1; i < allNodes.length - 1; i++) {
			allNodes[i] = new Node[inputNum];
			for(int j = 0; j < inputNum; j++) {
				int begin = j - affectRange / 2;
				if (begin < 0) {
					begin = 0;
				}
				int end = j + affectRange / 2;
				if (end >= inputNum) {
					end = inputNum - 1;
				}
				if (end < begin) {
					throw new Exception("end < begin");
				}
				allNodes[i][j].lastNodeIndexAndWeight = new HashMap<>();
				for (int k = begin; k <= end; k++) {
					allNodes[i][j].lastNodeIndexAndWeight.put(k, weightInitialValue);
				}
				allNodes[i][j].nextNodeIndexAndWeight = new HashMap<>();
				if (i != allNodes.length - 2) {
					for (int k = begin; k <= end; k++) {
						allNodes[i][j].nextNodeIndexAndWeight.put(k, weightInitialValue);
					}
				} else {
					allNodes[i][j].nextNodeIndexAndWeight.put(0, weightInitialValue);
				}
				allNodes[i][j].cita = weightInitialValue;
			}
		}
		//last layer, the output layer
		allNodes[allNodes.length - 1] = new Node[1];
		allNodes[allNodes.length - 1][0].nextNodeIndexAndWeight = null;
		allNodes[allNodes.length - 1][0].lastNodeIndexAndWeight = new HashMap<>();
		for (int k = 0; k < inputNum; k++) {
			allNodes[allNodes.length - 1][0].lastNodeIndexAndWeight.put(k, weightInitialValue);
		}
		allNodes[allNodes.length - 1][0].cita = weightInitialValue;
	}

	public void TrainNetwork(ArrayList<Data> allTrainData) {
		int index = 0;
		// int count = 0;
		while (true) {
			Data currentData = allTrainData.get(index);
			for (int i = 0; i < inputNum; i++) {
				allNodes[0][i].data = currentData.dataList[i];
			}
			float evaluatedValue = ForwardFeed();

			System.out.println("error: " + Math.abs(evaluatedValue - currentData.result));

			BackPropagation(evaluatedValue, currentData.result);
			// if (Math.abs(evaluatedValue - currentData.result) < 1e-3) {
			// count ++;
			// index++;
			// if (index == allTrainData.size()) {
			//
			// }
			// } else {
			//
			// }
		}
	}

	public void BackPropagation(float evaluatedValue, float realResult) {
		allNodes[hiddenLayerNum + 1][0].error = evaluatedValue * (1 - evaluatedValue) * (realResult - evaluatedValue);
		for (int i = 0; i < inputNum; i++) {
			weight[hiddenLayerNum][0][i] += learningRate * error[hiddenLayerNum][0] * tempResult[hiddenLayerNum][i];
		}
		cita[hiddenLayerNum][0] += learningRate * error[hiddenLayerNum][0];

		for (int i = hiddenLayerNum - 1; i >= 0; i--) {
			for (int j = 0; j < inputNum; j++) {
				float temp = 0;
				if (error[i + 1].length == 1) {
					temp += weight[hiddenLayerNum][0][j] * error[i + 1][0];
				} else {
					int begin = j - affectRange / 2;
					if (begin < 0) {
						begin = 0;
					}
					int end = j + affectRange / 2;
					if (end >= inputNum) {
						end = inputNum - 1;
					}
					for (int k = begin; k <= end; k++) {

						temp += weight[i + 1][k][k - begin] * error[i + 1][k];
					}
				}
				float o = tempResult[i + 1][j];
				error[i][j] = o * (1 - o) * temp;

				for (int k = 0; k < weight[i][j].length; k++) {
					weight[i][j][k] += learningRate * error[i][j] * tempResult[i][j];
				}
				cita[i][j] += learningRate * error[i][j];
			}
		}
	}

	public float ForwardFeed() {
		for (int i = 1; i <= hiddenLayerNum; i++) {
			for (int j = 0; j < inputNum; j++) {
				float temp = 0;
				for (Map.Entry<Integer, Float> entry : allNodes[i][j].lastNodeIndexAndWeight.entrySet()) {
					int lastIndex = entry.getKey();
					float lastWeight = entry.getValue();
					temp += lastWeight * allNodes[i - 1][lastIndex].data;
				}
				temp += allNodes[i][j].cita;
				allNodes[i][j].data = evaluate(temp);
			}
		}
		float temp = 0;
		for (Map.Entry<Integer, Float> entry : allNodes[hiddenLayerNum + 1][0].lastNodeIndexAndWeight.entrySet()) {
			int lastIndex = entry.getKey();
			float lastWeight = entry.getValue();
			temp += lastWeight * allNodes[hiddenLayerNum][lastIndex].data;
		}
		temp += allNodes[hiddenLayerNum + 1][0].cita;
		allNodes[hiddenLayerNum + 1][0].data = evaluate(temp);
		return allNodes[hiddenLayerNum + 1][0].data;
	}

	public static float evaluate(float a) {
		return (float) (1.0 / (1 + Math.exp(-a)));
	}
}
